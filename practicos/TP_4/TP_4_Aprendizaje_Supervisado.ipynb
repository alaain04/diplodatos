{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mentoría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje Supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente notebook se presentará la consigna a seguir para el cuarto práctico del proyecto, correspondiente a la materia Aprendizaje Automático Supervisado. El objetivo consiste en profundizar en la aplicación de métodos de aprendizaje supervisado aprendidos en el curso, así como también en métodos de ensemble learning. Esto, siempre a través de experimentos reproducibles y evaluando a su vez la conveniencia de uno u otro, así como la selección de diferentes hiperparámetros a partir del cálculo de las métricas pertinentes.\n",
    "\n",
    "A los fines de este práctico, consideraremos el problema original de nuestro proyecto, el cual consiste en un problema de regresión. Nuevamente, al igual que en el práctico anterior, será importante evaluar el desbalance de clases y qué decisiones tomaremos al respecto.\n",
    "\n",
    "Para ello, comenzaremos con las importaciones pertinentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de las librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Puede que nos sirvan también\n",
    "import matplotlib as mpl\n",
    "mpl.get_cachedir()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# import sklearn as skl\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, classification_report, roc_curve, auc\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "np.random.seed(0)  # Para mayor determinismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('max_colwidth', 151)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consigna para Aprendizaje Automático Supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Preprocesamiento\n",
    "\n",
    "A los fines de realizar este práctico, se utilizará el dataset energia_completo. La división entre train y test será realizada en este mismo práctico.\n",
    "A continuación se detallan los pasos a seguir para el preprocesamiento de los datos, prácticamente iguales a los del práctico anterior.\n",
    "\n",
    "#### 1. Obtención del Dataset\n",
    "\n",
    "Cargar el conjunto de entrenamiento original. Luego, eliminar las columnas calculadas en base a features preexistentes.\n",
    "\n",
    "#### 2. Aplicar Script de Curación\n",
    "\n",
    "Inicialmente, con el objetivo de preparar los datos que alimentarán los modelos de aprendizaje automático (ML) propuestos, deberán aplicar el script de curación obtenido en el segundo práctico.\n",
    "En esta etapa, nuevamente, pueden adicionar los atributos creados por ustedes que crean pertinentes a priori o que hayan encontrado interesantes por tener mayor correlación con la variable `Kwatts_3_fases`.\n",
    "\n",
    "#### 3. Análisis del Balance de Clases\n",
    "\n",
    "¿Cómo luce el balance de clases? ¿Tomarán alguna decisión al respecto?\n",
    "\n",
    "\n",
    "#### 4. Normalización de Atributos\n",
    "\n",
    "Es posible que sea necesario normalizar las features de nuestro dataset, dado que muchos de los algoritmos de clasificación supervisada lo requieren. ¿En qué casos tendrá que implementarse normalización, considerando los nuevos modelos propuestos?\n",
    "\n",
    "Aplicar al dataset la normalización de atributos que consideren adecuada.\n",
    "\n",
    "#### 5. Mezca Aleatória y División en Train/Test\n",
    "\n",
    "Finalmente, están en condiciones de **dividir el dataset en Train y Test**, utilizando para este último conjunto un 20% de los datos disponibles. Previo a esta división, es recomendable que mezclen los datos aleatoriamente.\n",
    "De este modo, deberán obtener cuatro conjuntos de datos, para cada uno de los datasets: ```X_train```, ```X_test```, ```y_train``` y ```y_test```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Aplicación de Modelos de Aprendizaje Automático Supervisado\n",
    "\n",
    "Una vez finalizada la etapa de preprocesamiento, se propone implementar diferentes modelos de regresión **para el dataset seleccionado**, utilizando la librería Scikit-Learn (o la que consideren apropiada):\n",
    "\n",
    "1. Support Vector Machines (SVM), probando distintos kernels para la regresión.\n",
    "2. Random Forest, utilizando parámetros de normalización cuando lo crean pertinente.\n",
    "3. Red neuronal.\n",
    "\n",
    "Para cada uno de ellos, se pide responder las siguientes consignas:\n",
    "- Utilizar dos features para graficar las clases y la frontera de decisión, siempre que sea posible.\n",
    "- Agregar vector de Bias, cuando lo crean pertinente. Cuándo hace falta y cuándo no? Por qué?\n",
    "\n",
    "De estos tres modelos, cuál creen que es el más adecuado para nuestro caso de aplicación?\n",
    "\n",
    "Finalmente, **combinar los modelos en un clasificador por votos** (pueden implementar VotingClassifier, del módulo de ensemble).\n",
    "\n",
    "**Elegir el modelo que consideren que mejor aplica a nuestro problema.** Para ello, recuerden que los pasos a seguir en la selección pueden esquematizarse como sigue:\n",
    "\n",
    "#### 1. Descripción de la Hipótesis\n",
    "\n",
    "¿Cuál es nuestro problema? ¿Cómo se caracteriza? ¿Cuál es la hipótesis?\n",
    "\n",
    "#### 2. Selección de Regularizador\n",
    "\n",
    " ¿Utilizarán algún regularizador?¿Cuál?\n",
    "\n",
    "#### 3. Selección de Función de Costo\n",
    "\n",
    "¿Cuál será la función de costo utilizada?\n",
    "\n",
    "#### 4. Justificación de las Selecciones\n",
    "\n",
    "¿Por qué eligieron el modelo, el regularizador y la función de costo previas?\n",
    "\n",
    "Finalmente, para el modelo selecionado:\n",
    "\n",
    "- Utilizar el método *Grid Search*, o de búsqueda exahustiva, con *cross-validation* para profundizar en la búsqueda y selección de hiperparámetros (fine tuning).\n",
    "- Calcular métricas sobre el conjunto de entrenamiento y de evaluación para los mejores parámetros obtenidos:\n",
    "   + Mean Absolute Error (MAE)\n",
    "   + Mean Squared Error (MSE)\n",
    "   + R2 Score\n",
    "   + Explaned Variance Score\n",
    "   \n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\n",
    "   \n",
    "- ¿Cuál consideran la métrica más apropiada para utilizar en nuestros modelos? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entregables\n",
    "\n",
    "El entregable de este práctico consiste en **esta misma Notebook**, pero con el preprocesamiento aplicado y los modelos implementados, agregando las explicaciones que crean pertinentes y las decisiones tomadas, en caso de corresponder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
