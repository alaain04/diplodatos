{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mentoría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje Supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente notebook se presentará la consigna a seguir para el quinto y último práctico del proyecto, correspondiente a la materia Aprendizaje Automático No Supervisado. El objetivo consiste en aplicar distintas técnicas de análisis exploratorio de datos (EDA) al dataset, de modo de encontrar patrones sistematizables.\n",
    "\n",
    "Luego, una vez aplicadas las técnicas de aprendizaje no supervisado y del cálculo de las métricas pertinentes, podremos recurrir a las etiquetas de clases con el fin de contrastar los resultados obtenidos.\n",
    "\n",
    "Para ello, comenzaremos con las importaciones pertinentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alain/miniconda3/envs/diplo/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.decomposition.pca module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.decomposition. Anything that cannot be imported from sklearn.decomposition is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importación de las librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Puede que nos sirvan también\n",
    "import matplotlib as mpl\n",
    "mpl.get_cachedir()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# import sklearn as skl\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition.pca import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 0\n",
    "np.random.seed(0)  # Para mayor determinismo\n",
    "\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('max_colwidth', 151)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Consigna para Aprendizaje Automático No Supervisado\n",
    "\n",
    "### I. Preprocesamiento\n",
    "\n",
    "A los fines de realizar este práctico, se utilizará el dataset original. A continuación se detallan los pasos a seguir para el preprocesamiento de los datos.\n",
    "\n",
    "#### 1. Obtención del Dataset\n",
    "\n",
    "Cargar el conjunto de entrenamiento original. Luego, eliminar las columnas calculadas en base a features preexistentes.\n",
    "\n",
    "#### 2. Aplicar Script de Curación\n",
    "\n",
    "Inicialmente, con el objetivo de preparar los datos que alimentarán los modelos de aprendizaje automático (ML) propuestos, deberán aplicar el script de curación obtenido en el segundo práctico. En esta etapa, nuevamente, pueden adicionar los atributos creados por ustedes que crean pertinentes a priori o que hayan encontrado interesantes por tener mayor correlación con la variable Kwatts_3_fases.\n",
    "\n",
    "#### 3. Normalización de Atributos\n",
    "\n",
    "Es posible que sea necesario normalizar las features de nuestro dataset, dado que los algoritmos de clasificación no supervisada lo requieren. Aplicar al dataset la normalización de atributos que consideren adecuada.\n",
    "\n",
    "#### 4. Mezca Aleatória y División en Train/Test\n",
    "\n",
    "Finalmente, es recomendable que mezclen los datos aleatoriamente, dado que la inicialización influye en los resultados del modelo que se propone que implementen.\n",
    "\n",
    "Respecto a la división en Train/Test, dado que se trata de un algoritmo de aprendizaje automático no supervisado, pueden omitir esta división, ya que estamos buscando patrones ocultos en los datos que reflejen las causas latentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Aplicación de Modelos de Aprendizaje Automático No Supervisado\n",
    "\n",
    "Una vez finalizada la etapa de preprocesamiento, se propone implementar, por un lado, una técnica de reducción de dimensionalidad para representar los datos y, por el otro, una técnica de clusterización.\n",
    "\n",
    "#### 1. Descomposivión de Variables: Principal Component Analysis\n",
    "\n",
    "Aplicar esta técnica de reducción de variables. A partir del análisis y la visualización de los datasets transformados por PCA, obtener conclusiones.\n",
    "\n",
    "Adicionalmente, existe una técnica similar llamada Factor Analysis. Aplicarla y obtener conclusiones. Comparar con los resultados obtenidos previamente.\n",
    "\n",
    "#### 2. K-Means Clustering\n",
    "\n",
    "Aplicar K-Means tanto a los dataset originales como a los datasets transformados a partir de cualquiera de las técnicas anteriores.\n",
    "\n",
    "Explorar distintas soluciones de clustering con diferentes parámetros, como iteraciones, número de clusters o métricas de distancia, y compararlas. Finalmente, para el modelo seleccionado:\n",
    "\n",
    "    Calcular las métricas pertinentes sobre los clusters resultantes.\n",
    "    Aplicando el método de Elbow, ¿cuál sería la cantidad óptima de clusters?\n",
    "    Agregar a los dataset originales el cluster resultante de los modelos.\n",
    "    Graficar diferentes variables de interés por cluster y por clase, y compararlos.\n",
    "    Tomar ejemplos aleatorios y pensar por qué están en un cluster y no en otro.\n",
    "    Calcular los centroides y tratar de mostrar qué tiene cada cluster cerca de su centroide. Obtener conclusiones.\n",
    "    Contrastar la clasificación en clusters con los valores de potencia asociados en el dataset original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Opcional - Tareas Adicionales\n",
    "Incluir clusters como una nueva feature en el modelo seleccionado en el práctico de aprendizaje supervisado.\n",
    "Probar los modelos con los nuevos datos disponibilizados.\n",
    "\n",
    "Obtener conclusiones de su aplicación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entregables\n",
    "\n",
    "El entregable de este práctico consiste en esta misma Notebook, pero con el preprocesamiento aplicado y las técnicas implementadas, agregando las explicaciones que crean pertinentes y las decisiones tomadas, en caso de corresponder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
